name: Build, Push and Test Ollama Model Image

on:
  workflow_dispatch:
    inputs:
      model_file:
        description: 'Select model metadata file'
        required: true
        default: 'gemma2_2b.yaml'
        type: choice
        options:
          - gemma2_2b.yaml
          - deepseek-r1_7b.yaml
          - deepseek-r1_1.5b.yaml
          - deepseek-r1_8b.yaml
          - mixtral_8x7b.yaml
          - gemma2_9b.yaml
          - gemma2_27b.yaml
          - all-minilm_33m.yaml

jobs:
  build:
    runs-on: ubuntu-latest
    outputs:
      model_name: ${{ steps.model.outputs.model_name }}
      model_tag: ${{ steps.model.outputs.model_tag }}
    steps:
      - name: Checkout repository
        uses: actions/checkout@v3

      - name: Set up Docker Buildx
        uses: docker/setup-buildx-action@v3

      - name: Install yq
        run: sudo snap install yq

      - name: Read model metadata
        id: model
        run: |
          MODEL_FILE="model_metadata/${{ github.event.inputs.model_file }}"
          MODEL_NAME=$(yq '.name' "$MODEL_FILE")
          MODEL_TAG=$(yq '.tag' "$MODEL_FILE")
          MODEL_SIZE=$(yq '.memory.model_size' "$MODEL_FILE")
          MEMORY_MIN=$(yq '.memory.min' "$MODEL_FILE")
          MEMORY_RECOMMENDED=$(yq '.memory.recommended' "$MODEL_FILE")
          LICENSE=$(yq '.license' "$MODEL_FILE")
          echo "MODEL_NAME=$MODEL_NAME" >> $GITHUB_ENV
          echo "MODEL_TAG=$MODEL_TAG" >> $GITHUB_ENV
          echo "MODEL_SIZE=$MODEL_SIZE" >> $GITHUB_ENV
          echo "MEMORY_MIN=$MEMORY_MIN" >> $GITHUB_ENV
          echo "MEMORY_RECOMMENDED=$MEMORY_RECOMMENDED" >> $GITHUB_ENV
          echo "LICENSE=$LICENSE" >> $GITHUB_ENV
          echo "model_name=$MODEL_NAME" >> $GITHUB_OUTPUT
          echo "model_tag=$MODEL_TAG" >> $GITHUB_OUTPUT

      - name: Preload Ollama model cache
        run: |
          mkdir -p ollama/model-cache
          docker run --rm \
            --entrypoint sh \
            -v ${{ github.workspace }}/ollama/model-cache:/root/.ollama \
            -e OLLAMA_ORCHESTRATOR=standalone \
            ollama/ollama:0.6.5 \
            -c "ollama serve & sleep 5 && ollama pull $MODEL_NAME:$MODEL_TAG"

      - name: Build Docker image
        run: |
          docker build \
            --build-arg MODEL_NAME=$MODEL_NAME \
            --build-arg MODEL_TAG=$MODEL_TAG \
            --label org.opencontainers.image.title="Ollama Server - $MODEL_NAME" \
            --label org.opencontainers.image.description="Preloaded Ollama model server for $MODEL_NAME:$MODEL_TAG" \
            --label org.opencontainers.image.version="$MODEL_TAG" \
            --label org.opencontainers.image.authors="Sinan Ozel" \
            --label org.opencontainers.image.licenses="$LICENSE" \
            --label org.opencontainers.image.vendor="sinanozel" \
            --label org.opencontainers.image.memory.size="$MODEL_SIZE" \
            --label org.opencontainers.image.memory.min="$MEMORY_MIN" \
            --label org.opencontainers.image.memory.recommended="$MEMORY_RECOMMENDED" \
            -t model-servers/ollama-server-$MODEL_NAME:$MODEL_TAG \
            -f ./ollama/Dockerfile ./ollama

      - name: Save Docker image as artifact
        run: |
          docker save model-servers/ollama-server-$MODEL_NAME:$MODEL_TAG -o ollama-server.tar

      - name: Upload image artifact
        uses: actions/upload-artifact@v4
        with:
          name: ollama-server
          path: ollama-server.tar

  test:
    needs: build
    runs-on: ubuntu-latest
    steps:
      - name: Download image artifact
        uses: actions/download-artifact@v4
        with:
          name: ollama-server
      - name: Load Docker image
        run: |
          docker load -i ollama-server.tar

      - name: List Docker image
        run: |
          docker image list


      - name: Test model library and blobs (ENTRYPOINT override)
        run: |
          IMAGE_NAME=model-servers/ollama-server-${{ needs.build.outputs.model_name }}:${{ needs.build.outputs.model_tag }}

          echo "ðŸš€ Creating container with overridden entrypoint..."
          CONTAINER_ID=$(docker create --entrypoint "" "$IMAGE_NAME" bash -c 'test -f /root/.ollama/models/manifest/ && ls -A /root/.ollama/models/blobs/sha256')

          echo "ðŸ” Starting container to verify model presence..."
          docker start -a "$CONTAINER_ID"

          echo "ðŸ§¹ Cleaning up container..."
          docker rm "$CONTAINER_ID"

      # docker cp "$CONTAINER_ID:/root/.ollama/models/blobs/sha256" ./model-blobs

      # - name: Test model file (inspect only)
      #   run: |
      #     IMAGE_NAME=model-servers/ollama-server-${{ needs.build.outputs.model_name }}:${{ needs.build.outputs.model_tag }}
      #     CONTAINER_ID=$(docker create "$IMAGE_NAME")
      #     docker cp "$CONTAINER_ID:/root/.ollama/models/" ./model-blobs
      #     docker rm "$CONTAINER_ID"
      #     if [ -z "$(ls -A ./model-blobs)" ]; then
      #       echo "Model not found in image"
      #       exit 1
      #     else
      #       echo "Model files found:"
      #       ls ./model-blobs
      #     fi

      # - name: Test model library (inspect only)
      #   run: |
      #     IMAGE_NAME=model-servers/ollama-server-${{ needs.build.outputs.model_name }}:${{ needs.build.outputs.model_tag }}
      #     CONTAINER_ID=$(docker create "$IMAGE_NAME")
      #     docker cp "$CONTAINER_ID:/root/.ollama/models/library.json" ./library.json
      #     docker rm "$CONTAINER_ID"

      #     echo "ðŸ“„ Contents of library.json:"
      #     cat ./library.json

      #     echo "ðŸ” Checking if model '${{ needs.build.outputs.model_name }}:${{ needs.build.outputs.model_tag }}' exists..."
      #     MODEL_ENTRY=$(jq -r --arg name "${{ needs.build.outputs.model_name }}" --arg tag "${{ needs.build.outputs.model_tag }}" '.models[] | select(.name == $name and .tag == $tag)' ./library.json)

      #     if [ -z "$MODEL_ENTRY" ]; then
      #       echo "âŒ Model entry not found in library.json"
      #       exit 1
      #     else
      #       echo "âœ… Model entry found:"
      #       echo "$MODEL_ENTRY"
      #     fi


      # - name: Test model preload
      #   run: |
      #     docker run --rm model-servers/ollama-server-$MODEL_NAME:$MODEL_TAG curl -s http://localhost:11434/api/generate -d '{"model": "'"$MODEL_NAME""}',"prompt":"2 + 2 ="}' || (echo "Model not loaded" && exit 1)

  push:
    needs: test
    runs-on: ubuntu-latest
    env:
      AWS_REGION: ca-central-1
    steps:
      - name: Download image artifact
        uses: actions/download-artifact@v4
        with:
          name: ollama-server

      - name: Load Docker image
        run: |
          docker load -i ollama-server.tar
      - name: Configure AWS credentials
        uses: aws-actions/configure-aws-credentials@v2
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-region: ${{ env.AWS_REGION }}

      - name: Log in to Docker Hub
        uses: docker/login-action@v3
        with:
          username: ${{ secrets.DOCKER_USERNAME }}
          password: ${{ secrets.DOCKER_TOKEN }}

      - name: Tag Docker image for Docker Hub
        run: |
          docker tag model-servers/ollama-server-${{ needs.build.outputs.model_name }}:${{ needs.build.outputs.model_tag }} \
            ${{ secrets.DOCKER_USERNAME }}/model-servers/ollama-server-${{ needs.build.outputs.model_name }}:${{ needs.build.outputs.model_tag }}

      - name: Push to Docker Hub
        run: |
          docker push ${{ secrets.DOCKER_USERNAME }}/model-servers/ollama-server-${{ needs.build.outputs.model_name }}:${{ needs.build.outputs.model_tag }}

      - name: Get AWS Account ID
        id: aws
        run: echo "account_id=$(aws sts get-caller-identity --query Account --output text)" >> $GITHUB_OUTPUT

      - name: Tag Docker image for ECR
        run: |
          ECR_URI="${{ steps.aws.outputs.account_id }}.dkr.ecr.${{ env.AWS_REGION }}.amazonaws.com/model-servers/ollama-server-${{ needs.build.outputs.model_name }}:${{ needs.build.outputs.model_tag }}"
          docker tag model-servers/ollama-server-${{ needs.build.outputs.model_name }}:${{ needs.build.outputs.model_tag }} $ECR_URI

      - name: Login to ECR
        run: |
          aws ecr get-login-password --region $AWS_REGION | docker login --username AWS --password-stdin ${{ steps.aws.outputs.account_id }}.dkr.ecr.${{ env.AWS_REGION }}.amazonaws.com

      - name: Create repository if it doesn't exist
        run: |
          aws ecr describe-repositories --repository-names model-servers/ollama-server-${{ needs.build.outputs.model_name }} --region $AWS_REGION || \
          aws ecr create-repository --repository-name model-servers/ollama-server-${{ needs.build.outputs.model_name }} --region $AWS_REGION

      - name: Push to AWS ECR
        run: |
          docker push ${{ steps.aws.outputs.account_id }}.dkr.ecr.${{ env.AWS_REGION }}.amazonaws.com/model-servers/ollama-server-${{ needs.build.outputs.model_name }}:${{ needs.build.outputs.model_tag }}
